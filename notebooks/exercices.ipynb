{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CACBFsndOCo"
      },
      "source": [
        "# Exercices"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Préliminaires**: Clone de votre repo et imports"
      ],
      "metadata": {
        "id": "hfkMtaHleKAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Zakaria-Yahya/exam_2025.git\n",
        "! cp exam_2025/utils/utils_exercices.py .\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "xiD_cI-geJjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88110170-8b7d-454e-9387-d0dd7e11006f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'exam_2025' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clef personnelle pour la partie théorique**\n",
        "\n",
        "Dans la cellule suivante, choisir un entier entre 100 et 1000 (il doit être personnel). Cet entier servira de graine au générateur de nombres aléatoire a conserver pour tous les exercices.\n",
        "\n"
      ],
      "metadata": {
        "id": "J3ga_6BNc5DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mySeed = 388"
      ],
      "metadata": {
        "id": "PrCTHM4od5UZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "TRWBLVpCWC06"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5RcggmAkJLV"
      },
      "source": [
        "\\\n",
        "\n",
        "**Exercice 1** *Une relation linéaire*\n",
        "\n",
        "La fonction *generate_dataset* fournit deux jeux de données (entraînement et test). Pour chaque jeu de données, la clef 'inputs' donne accès à un tableau numpy (numpy array) de prédicteurs empilés horizontalement : chaque ligne $i$ contient trois prédicteurs $x_i$, $y_i$ et $z_i$. La clef 'targets' renvoie le vecteur des cibles $t_i$. \\\n",
        "\n",
        "Les cibles sont liées aux prédicteurs par le modèle:\n",
        "$$ t = \\theta_0 + \\theta_1 x + \\theta_2 y + \\theta_3 z + \\epsilon$$ où $\\epsilon \\sim \\mathcal{N}(0,\\eta)$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_exercices import generate_dataset, Dataset1\n",
        "train_set, test_set = generate_dataset(mySeed)"
      ],
      "metadata": {
        "id": "gEQmgTI8my8i"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Par quelle méthode simple peut-on estimer les coefficients $\\theta_k$ ? La mettre en oeuvre avec la librairie python de votre choix."
      ],
      "metadata": {
        "id": "q5XZTrXNk12K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Réponse:\n",
        "La méthode la plus simple et la plus efficace pour estimer les coefficients (θ) dans un modèle de régression linéaire comme celui-ci est d'utiliser les moindres carrés ordinaires (OLS)."
      ],
      "metadata": {
        "id": "gDgh0UzhZU6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraire les entrées (X) et les cibles (y) de l'ensemble d'apprentissage\n",
        "X = torch.tensor(train_set['inputs'], dtype=torch.float32)\n",
        "y = torch.tensor(train_set['targets'], dtype=torch.float32)\n",
        "\n",
        "# Ajouter une colonne de uns à X pour le terme d'interception (θ0)\n",
        "X = torch.cat([torch.ones(X.shape[0], 1), X], dim=1)\n",
        "\n",
        "# Calculer les coefficients OLS à l'aide de la formule : θ = (X^T X)^-1 X^T y\n",
        "theta = torch.linalg.solve(X.T @ X, X.T @ y)\n",
        "\n",
        "# Afficher les coefficients estimés\n",
        "print(\"Coefficients estimés (θ) :\", theta)\n",
        "\n",
        "# Calculate predictions\n",
        "predictions = X @ theta\n",
        "\n",
        "# Calculate error (Mean Squared Error - MSE)\n",
        "error = torch.mean((predictions - y)**2)\n",
        "\n",
        "# Print the error\n",
        "print(\"Mean Squared Error (MSE):\", error)"
      ],
      "metadata": {
        "id": "HITtUqHhFMkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df10d0c-b477-442b-8a6e-5237514e3d8b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients estimés (θ) : tensor([19.3857,  3.9040,  3.8649,  7.5905])\n",
            "Mean Squared Error (MSE): tensor(3.9825)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MXGXg8tlPULY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans les cellules suivantes, on se propose d'estimer les $\\theta_k$ grâce à un réseau de neurones entraîné par SGD. Quelle architecture s'y prête ? Justifier en termes d'expressivité et de performances en généralisation puis la coder dans la cellule suivante."
      ],
      "metadata": {
        "id": "CH_Z5ZEIlQPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Réponse:\n",
        "\n",
        "Expressivité : Une seule couche linéaire est suffisante pour apprendre une relation linéaire. Ajouter des couches supplémentaires ou des non-linéarités serait superflu et risquerait de dégrader les performances en généralisation.\n",
        "\n",
        "Performances en généralisation : Une architecture simple réduit le risque de sur-apprentissage (overfitting), surtout avec un bruit gaussien (ϵ∼N(0,η)). Cela garantit une bonne performance sur des données non vues."
      ],
      "metadata": {
        "id": "qFss527GcByM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset et dataloader :\n",
        "dataset = Dataset1(train_set['inputs'], train_set['targets'])\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "import torch.nn as nn\n",
        "\n",
        "# A coder :\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "PPx543blnxdb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Entraîner cette architecture à la tâche de régression définie par les entrées et sorties du jeu d'entraînement (compléter la cellule ci-dessous)."
      ],
      "metadata": {
        "id": "g6BSTBitpGBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "mySimpleNet = SimpleNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(mySimpleNet.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_inputs, batch_targets in dataloader:\n",
        "\n",
        "        # Mise en mode entraînement\n",
        "        mySimpleNet.train()\n",
        "\n",
        "        # Étape forward : calcul des prédictions\n",
        "        predictions = mySimpleNet(batch_inputs)\n",
        "\n",
        "        # Calcul de la perte\n",
        "        loss = criterion(predictions, batch_targets.unsqueeze(1))  # Ajouter une dimension pour le batch\n",
        "\n",
        "        # Étape backward : calcul des gradients\n",
        "        optimizer.zero_grad()  # Remise à zéro des gradients\n",
        "        loss.backward()  # Calcul des gradients\n",
        "\n",
        "        # Mise à jour des paramètres\n",
        "        optimizer.step()\n",
        "\n",
        "    # Affichage de la perte pour suivre l'entraînement\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        ""
      ],
      "metadata": {
        "id": "Wjfa2Z4RoPO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59820346-574b-4dc9-bf8f-308c8ac80f77"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/500], Loss: 3.7808\n",
            "Epoch [100/500], Loss: 5.1837\n",
            "Epoch [150/500], Loss: 3.2892\n",
            "Epoch [200/500], Loss: 3.6998\n",
            "Epoch [250/500], Loss: 3.9494\n",
            "Epoch [300/500], Loss: 5.0093\n",
            "Epoch [350/500], Loss: 4.0476\n",
            "Epoch [400/500], Loss: 3.1325\n",
            "Epoch [450/500], Loss: 4.0927\n",
            "Epoch [500/500], Loss: 3.4747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Où sont alors stockées les estimations des  $\\theta_k$ ? Les extraire du réseau *mySimpleNet* dans la cellule suivante."
      ],
      "metadata": {
        "id": "OZwKogEEp2Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accéder aux paramètres de la couche linéaire\n",
        "linear_layer_params = mySimpleNet.fc.parameters()\n",
        "\n",
        "# Extraire les poids et le biais\n",
        "weights = next(iter(linear_layer_params)).detach().numpy()  # poids (θ1, θ2, θ3)\n",
        "bias = next(iter(linear_layer_params)).detach().numpy()  # biais (θ0)\n",
        "\n",
        "# Afficher les estimations des coefficients\n",
        "print(\"Poids (θ1, θ2, θ3) :\", weights)\n",
        "print(\"Biais (θ0) :\", bias)"
      ],
      "metadata": {
        "id": "EjgWp1y1rseb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff75b215-9d04-46b4-d5aa-f8ab1f4955bd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poids (θ1, θ2, θ3) : [[3.904183  3.8635218 7.58983  ]]\n",
            "Biais (θ0) : [19.384892]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** Tester ces estimations sur le jeu de test et comparer avec celles de la question 1. Commentez."
      ],
      "metadata": {
        "id": "pEB-V-oOrJED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Charger les données de test\n",
        "test_inputs = test_set['inputs']  # Prédicteurs du jeu de test\n",
        "test_targets = test_set['targets']  # Cibles réelles du jeu de test\n",
        "\n",
        "# Déplacer les données sur le même appareil que le modèle\n",
        "test_inputs = torch.tensor(test_inputs, dtype=torch.float32)\n",
        "\n",
        "# Générer les prédictions à l'aide du modèle\n",
        "mySimpleNet.eval()  # Mettre le modèle en mode évaluation\n",
        "with torch.no_grad():  # Pas de calcul de gradients\n",
        "    predictions = mySimpleNet(test_inputs).numpy().flatten()  # Prédictions aplaties\n",
        "\n",
        "# Calculer l'erreur quadratique moyenne (MSE) entre les prédictions et les cibles\n",
        "mse_test = np.mean((predictions - test_targets) ** 2)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(f\"Erreur quadratique moyenne (MSE) sur le jeu de test : {mse_test:.4f}\")\n",
        "\n",
        "# Comparaison avec les résultats obtenus dans la question 1\n",
        "# Si vous avez les prédictions ou coefficients précédents, insérez-les ici pour comparaison\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ILBESLbgxpV",
        "outputId": "8632b50e-077e-461e-df06-cb1dd5816471"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erreur quadratique moyenne (MSE) sur le jeu de test : 3.8208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparaison des erreurs quadratiques moyennes (MSE) :\n",
        "\n",
        "MSE sur le jeu de test avec le réseau de neurones : 3.8208\\\n",
        "MSE obtenu dans la question 1  :\n",
        "3.9825\n",
        "\n",
        "La MSE obtenue avec le réseau de neurones est légèrement inférieure à celle obtenue dans la question 1, ce qui montre que la deuxième méthode est plus efficace mais la première est plus optimale en terme de temps."
      ],
      "metadata": {
        "id": "VvV2jIrBNtzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 2** *Champ réceptif et prédiction causale*"
      ],
      "metadata": {
        "id": "CpRvXCaAtsIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le réseau défini dans la cellule suivante est utilisé pour faire le lien entre les valeurs $(x_{t' \\leq t})$ d'une série temporelle d'entrée et la valeur présente $y_t$ d'une série temporelle cible."
      ],
      "metadata": {
        "id": "8JG9wTfK5TBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from utils_exercices import Outconv, Up_causal, Down_causal\n",
        "\n",
        "class Double_conv_causal(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2, with causal convolutions that preserve input size'''\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, dilation=1):\n",
        "        super(Double_conv_causal, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn1 = nn.BatchNorm1d(out_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm1d(out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class causalFCN(nn.Module):\n",
        "    def __init__(self, dilation=1):\n",
        "        super(causalFCN, self).__init__()\n",
        "        size = 64\n",
        "        n_channels = 1\n",
        "        n_classes = 1\n",
        "        self.inc = Double_conv_causal(n_channels, size)\n",
        "        self.down1 = Down_causal(size, 2*size)\n",
        "        self.down2 = Down_causal(2*size, 4*size)\n",
        "        self.down3 = Down_causal(4*size, 8*size, pooling_kernel_size=5, pooling_stride=5)\n",
        "        self.down4 = Down_causal(8*size, 4*size, pooling=False, dilation=2)\n",
        "        self.up2 = Up_causal(4*size, 2*size, kernel_size=5, stride=5)\n",
        "        self.up3 = Up_causal(2*size, size)\n",
        "        self.up4 = Up_causal(size, size)\n",
        "        self.outc = Outconv(size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up2(x5, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return x\n",
        "\n",
        "# Exemple d'utilisation\n",
        "model = causalFCN()\n",
        "# Série temporelle d'entrée (x_t):\n",
        "input_tensor1 = torch.rand(1, 1, 10000)\n",
        "# Série temporelle en sortie f(x_t):\n",
        "output = model(input_tensor1)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "fIbU1EJT1MM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbb10f4-e685-49ec-d598-1355f87de012"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** De quel type de réseau de neurones s'agit-il ? Combien de paramètres la couche self.Down1 compte-t-elle (à faire à la main) ?\n",
        "Combien de paramètres le réseau entier compte-t-il (avec un peu de code) ?"
      ],
      "metadata": {
        "id": "-mNnsYU-7R7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type de réseau : Le réseau présenté est un Fully Convolutional Network (FCN).\n",
        "# Nb de paramètres dans self.Down1: (calcul \"à la main\")\n",
        "# Nombre de paramètres = 64×128×3 + 128 = 24704\n",
        "# Nb de paramètres au total:\n",
        "# Calculer le nombre total de paramètres dans le réseau\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Nombre total de paramètres du réseau : {total_params}\")"
      ],
      "metadata": {
        "id": "qlYxUf6U9vH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb947fc-e500-4a55-d163-4489feb8b86c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total de paramètres du réseau : 2872641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Par quels mécanismes la taille du vecteur d'entrée est-elle réduite ? Comment est-elle restituée dans la deuxième partie du réseau ?"
      ],
      "metadata": {
        "id": "I4D46A0-8LaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reponse:\n",
        "\n",
        "La taille du vecteur d'entrée est réduite à traver la fonction Down_causal.\\\n",
        "Elle restutié à l'aide de Up_causal"
      ],
      "metadata": {
        "id": "vjtuXnd-nWtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fsqjXc-3mL4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Par quels mécanismes le champ réceptif est-il augmenté ? Préciser par un calcul la taille du champ réceptif en sortie de *self.inc*."
      ],
      "metadata": {
        "id": "SVNeFnm88yV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le champ réceptif est augmenté par l'empilement de couches de convolution et la dilatation, permettant aux neurones de capter des informations sur une zone plus large de l'entrée. La couche self.inc, composée de deux convolutions causales avec un kernel_size de 3 et une dilation de 1, a un champ réceptif en sortie de 5, calculé comme suit: 1 (initial) + 3 (1ère convolution) + (3-1) (2ème convolution) = 5."
      ],
      "metadata": {
        "id": "IIiAzXHKpYCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Par un bout de code, déterminer empiriquement la taille du champ réceptif associé à la composante $y_{5000}$ du vecteur de sortie. (Indice: considérer les sorties associées à deux inputs qui ne diffèrent que par une composante...)"
      ],
      "metadata": {
        "id": "TVVcBPuA9EP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Créer deux entrées qui ne diffèrent que par une composante\n",
        "input1 = torch.zeros(1, 1, 10000)\n",
        "input2 = input1.clone()\n",
        "input2[0, 0, 5000] = 1  # Modifier une seule composante\n",
        "\n",
        "# Obtenir les sorties du modèle pour les deux entrées\n",
        "model.eval()  # Mettre le modèle en mode évaluation\n",
        "with torch.no_grad():\n",
        "    output1 = model(input1)\n",
        "    output2 = model(input2)\n",
        "\n",
        "# Calculer la différence entre les sorties\n",
        "diff = output2 - output1\n",
        "\n",
        "# Trouver les indices des composantes non nulles dans la différence\n",
        "receptive_field_indices = torch.nonzero(diff.squeeze())\n",
        "\n",
        "# Calculer la taille du champ réceptif\n",
        "receptive_field_size = receptive_field_indices[-1] - receptive_field_indices[0] + 1\n",
        "\n",
        "# Afficher la taille du champ réceptif\n",
        "print(\"Taille du champ réceptif :\", receptive_field_size.item())"
      ],
      "metadata": {
        "id": "69WMWCSZAg5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee544458-aa01-411e-c724-ce5c6e67dc7c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du champ réceptif : 305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** $y_{5000}$ dépend-elle des composantes $x_{t, \\space t > 5000}$ ? Justifier de manière empirique puis préciser la partie du code de Double_conv_causal qui garantit cette propriété de \"causalité\" en justifiant.  \n",
        "\n"
      ],
      "metadata": {
        "id": "gZ37skwm-Vpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non, $𝑦_{5000}$ ne dépend pas des composantes $x_{t, \\space t > 5000}$. Le champ réceptif empirique est de 305, donc $𝑦_{5000}$ dépend uniquement de 𝑥𝑡 pour 4696≤𝑡≤5000 . Le padding causal dans Double_conv_causal, garantit la causalité en ajoutant des zéros uniquement du côté gauche de l'entrée, empêchant la convolution de \"voir\" les valeurs futures."
      ],
      "metadata": {
        "id": "59BxF4kzq6nB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PeooRYE-ATGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "qV52tusgNn6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "Exercice 3: \"Ranknet loss\""
      ],
      "metadata": {
        "id": "bm-sRzmfqc2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un [article récent](https://https://arxiv.org/abs/2403.14144) revient sur les progrès en matière de learning to rank. En voilà un extrait :"
      ],
      "metadata": {
        "id": "Wl8wUjsSM57D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "texte en italique\n",
        "<img src=\"https://raw.githubusercontent.com/nanopiero/exam_2025/refs/heads/main/utils/png_exercice3.PNG?token=GHSAT0AAAAAAC427DACOPGNDNN6UDOLVLLAZ4BB2JQ\" alt=\"extrait d'un article\" width=\"800\">"
      ],
      "metadata": {
        "id": "SDZUXMlSDpoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pQaa6Uxus2Mk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Qu'est-ce que les auteurs appellent \"positive samples\" et \"negative samples\" ? Donner un exemple."
      ],
      "metadata": {
        "id": "9NzV1PbMNyuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Réponse:\n",
        "\n",
        "Les \"positive samples\" désignent les échantillons qui sont jugés pertinents pour une requête donnée, tandis que les \"negative samples\" désignent ceux qui sont jugés non pertinents."
      ],
      "metadata": {
        "id": "Imi5vwBvszaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans l'expression de $\\mathcal{L}_{RankNet}$, d'où proviennent les $z_i$ ? Que représentent-ils ?  "
      ],
      "metadata": {
        "id": "yIKQ5Eo9OnPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Réponse:\n",
        "Les zi\n",
        "  proviennent du modèle de prédiction. Ils représentent les scores prévus par le modèle pour chaque échantillon.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mHXx2ukQs_Gv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Pourquoi cette expression conduit-elle à ce que, après apprentissage, \"the estimated\n",
        "value of positive samples is greater than that of negative samples\n",
        "for each pair of positive/negative samples\" ?"
      ],
      "metadata": {
        "id": "r74fWiyvPb7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'expression $\\mathcal{L}_{RankNet}$ inclut une fonction log-sigmoïde (\n",
        "𝜎(𝑧𝑖 − 𝑧𝑗)\n",
        " )) qui maximise la probabilité que le score\n",
        "zi  soit supérieur à zj\n",
        "  pour un échantillon positif (yij = 1) et minimise cette probabilité pour un échantillon négatif (yij = 0). Par conséquent, l'optimisation de cette fonction de perte pousse le modèle à produire des scores (zi > zj)\n",
        "  pour des paires positives/négatives, ce qui garantit que les échantillons positifs obtiennent des scores supérieurs aux échantillons négatifs."
      ],
      "metadata": {
        "id": "qH6x0TXTt4T1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Dans le cadre d'une approche par deep learning, quels termes utilise-t-on pour qualifier les réseaux de neurones exploités et la modalité suivant laquelle ils sont entraînés ?"
      ],
      "metadata": {
        "id": "pk1EIi_VVi3R"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}